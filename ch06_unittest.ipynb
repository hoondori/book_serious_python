{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed25563",
   "metadata": {},
   "source": [
    "# 단위 테스트 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20bf1d",
   "metadata": {},
   "source": [
    "## 테스트 스킵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848b051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pytest\r\n",
      "\r\n",
      "try:\r\n",
      "    import mylib\r\n",
      "except:\r\n",
      "    mylib = None\r\n",
      "    \r\n",
      "@pytest.mark.skip(\"Do not run this\")\r\n",
      "def test_fail():\r\n",
      "    assert False\r\n",
      "    \r\n",
      "@pytest.mark.skipif(mylib is None, reason='mylib is not available')\r\n",
      "def test_mylib():\r\n",
      "    assert mylib.foobar() == 42\r\n",
      "    \r\n",
      "def test_skip_at_runtime():\r\n",
      "    if True:\r\n",
      "        pytest.skip('Skp this')\r\n",
      "        \r\n",
      "        "
     ]
    }
   ],
   "source": [
    "!cat ./tests/test_skip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c146b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pytest -v ./tests/test_skip.py\n",
    "================================================================================= test session starts =================================================================================\n",
    "collected 3 items                                                                                                                                                                     \n",
    "\n",
    "tests/test_skip.py::test_fail SKIPPED (Do not run this)                                                                                                                         [ 33%]\n",
    "tests/test_skip.py::test_mylib SKIPPED (mylib is not available)                                                                                                                 [ 66%]\n",
    "tests/test_skip.py::test_skip_at_runtime SKIPPED (Skp this)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6a6ae0",
   "metadata": {},
   "source": [
    "## -k 로 특정 테스트만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc57237",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pytest -v ./tests/test_skip.py -k test_fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d61743",
   "metadata": {},
   "source": [
    "## 키워드로 마킹하여 필터링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6774b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pytest\r\n",
      " \r\n",
      "@pytest.mark.dicttest(\"This is dicttest\")\r\n",
      "def test_dicttest_1():\r\n",
      "    assert True\r\n",
      "\r\n",
      "@pytest.mark.dicttest(\"This is dicttest\")\r\n",
      "def test_dicttest_2():\r\n",
      "    assert True\r\n",
      "\r\n",
      "@pytest.mark.listtest(\"This is listtest\")\r\n",
      "def test_listtest1():\r\n",
      "    assert True\r\n",
      "\r\n",
      "@pytest.mark.listtest(\"This is listtest\")\r\n",
      "def test_listtest2():\r\n",
      "    assert True\r\n",
      "\r\n",
      "def test_somethingelse():\r\n",
      "    assert False"
     ]
    }
   ],
   "source": [
    "!cat ./tests/test_marking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pytest -v ./tests/test_marking.py -m dicttest\n",
    "================================================================================= test session starts =================================================================================\n",
    "collected 5 items / 3 deselected / 2 selected                                                                                                                                         \n",
    "\n",
    "tests/test_marking.py::test_dicttest_1 PASSED                                                                                                                                   [ 50%]\n",
    "tests/test_marking.py::test_dicttest_2 PASSED  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08a22e",
   "metadata": {},
   "source": [
    "## 병렬 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c943dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytest-xdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pytest -v ./tests/test_marking.py -m dicttest -n 2\n",
    "================================================================================= test session starts =================================================================================\n",
    "plugins: typeguard-2.10.0, xdist-2.3.0, forked-1.3.0, requests-mock-1.8.0\n",
    "[gw0] Python 3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56)  -- [GCC 7.3.0]\n",
    "[gw1] Python 3.6.12 |Anaconda, Inc.| (default, Sep  8 2020, 23:10:56)  -- [GCC 7.3.0]\n",
    "gw0 [2] / gw1 [2]\n",
    "scheduling tests via LoadScheduling\n",
    "\n",
    "tests/test_marking.py::test_dicttest_2 \n",
    "tests/test_marking.py::test_dicttest_1 \n",
    "[gw1] [ 50%] PASSED tests/test_marking.py::test_dicttest_2 \n",
    "[gw0] [100%] PASSED tests/test_marking.py::test_dicttest_1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933e3bc",
   "metadata": {},
   "source": [
    "## fixture autouse 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8293b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pytest\r\n",
      "import os\r\n",
      " \r\n",
      "@pytest.fixture(autouse=True)\r\n",
      "def change_user_env():\r\n",
      "    # before\r\n",
      "    curuser = os.environ.get(\"USER\")\r\n",
      "    os.environ[\"USER\"] = \"foobar\"\r\n",
      "    yield\r\n",
      "    \r\n",
      "    # after\r\n",
      "    os.environ[\"USER\"] = curuser\r\n",
      "\r\n",
      "\r\n",
      "def test_somethingelse():\r\n",
      "    assert os.getenv(\"USER\") == \"foobar\""
     ]
    }
   ],
   "source": [
    "!cat ./tests/test_fixture.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721928d",
   "metadata": {},
   "source": [
    "## 매개변수화된 test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364bd4d2",
   "metadata": {},
   "source": [
    "### 매개변수화된 단위 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45ad6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pytest\r\n",
      "\r\n",
      "\r\n",
      "@pytest.mark.parametrize(\"test_input,expected\", [(\"3+5\", 8), (\"2+4\", 6), (\"6*9\", 42)])\r\n",
      "def test_eval(test_input, expected):\r\n",
      "    assert eval(test_input) == expected\r\n"
     ]
    }
   ],
   "source": [
    "!cat tests/test_parameterized.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "$>pytest --collect-only ./tests/test_parameterized.py \n",
    "==================================================================================================================== test session starts =====================================================================================================================\n",
    "collected 3 items                                                                                                                                                                                                                                            \n",
    "\n",
    "<Module tests/test_parameterized.py>\n",
    "  <Function test_eval[3+5-8]>\n",
    "  <Function test_eval[2+4-6]>\n",
    "  <Function test_eval[6*9-42]>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f88875",
   "metadata": {},
   "source": [
    "### 매개변수화된 fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2afbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pytest\r\n",
      "import os\r\n",
      " \r\n",
      "@pytest.fixture(params=[\"mysql\", \"maria\"])\r\n",
      "def database(request):\r\n",
      "    yield request.param\r\n",
      "    \r\n",
      "def test_somethingElse(database):\r\n",
      "    assert 0 # for demo purpose\r\n"
     ]
    }
   ],
   "source": [
    "!cat tests/test_param_fixture.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pytest  --collect-only ./tests/test_param_fixture.py \n",
    "==================================================================================================================== test session starts =====================================================================================================================\n",
    "collected 2 items                                                                                                                                                                                                                                            \n",
    "\n",
    "<Module tests/test_param_fixture.py>\n",
    "  <Function test_somethingElse[mysql]>\n",
    "  <Function test_somethingElse[maria]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d7071",
   "metadata": {},
   "source": [
    "## 모의 객체를 이용한 제어된 테스트하기 \n",
    "\n",
    "https://docs.python.org/ko/3/library/unittest.mock-examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de1435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unittest import mock\n",
    "m = mock.Mock()\n",
    "m.some_method.return_value = 42\n",
    "m.some_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f9bdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_hello():\n",
    "    print(\"hello world\")\n",
    "    return 43\n",
    "\n",
    "m.some_method2.side_effect = print_hello\n",
    "m.some_method2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fc0874b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.some_method2.call_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd066a",
   "metadata": {},
   "source": [
    "### 호출 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "501ef11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Mock name='mock.some_method()' id='139719259290032'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unittest import mock\n",
    "m = mock.Mock()\n",
    "m.some_method('foo', 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d30b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.some_method.assert_called_once_with('foo', 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf2efaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Expected call: some_method('foo', 'bazzz')\nActual call: some_method('foo', 'bar')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-275e9b0dab8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msome_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_called_once_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bazzz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hoondori/anaconda3/envs/ai/lib/python3.6/unittest/mock.py\u001b[0m in \u001b[0;36massert_called_once_with\u001b[0;34m(_mock_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m                    (self._mock_name or 'mock', self.call_count))\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_called_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoondori/anaconda3/envs/ai/lib/python3.6/unittest/mock.py\u001b[0m in \u001b[0;36massert_called_with\u001b[0;34m(_mock_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0mcause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected call: some_method('foo', 'bazzz')\nActual call: some_method('foo', 'bar')"
     ]
    }
   ],
   "source": [
    "m.some_method.assert_called_once_with('foo', 'bazzz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47424bdb",
   "metadata": {},
   "source": [
    "### 패치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f5f587",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Testing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e425138e437a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'os.unlink'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_os_unlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foobar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-e425138e437a>\u001b[0m in \u001b[0;36mfake_os_unlink\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfake_os_unlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'os.unlink'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_os_unlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Testing"
     ]
    }
   ],
   "source": [
    "from unittest import mock\n",
    "import os\n",
    "def fake_os_unlink(path):\n",
    "    raise IOError(\"Testing\")\n",
    "    \n",
    "with mock.patch('os.unlink', fake_os_unlink):\n",
    "    os.unlink('foobar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import mock\n",
    "import requests\n",
    "\n",
    "def get_fake_get(status_code, content):\n",
    "    m = mock.Mock()\n",
    "    m.status_code = status_code\n",
    "    m.content = content\n",
    "\n",
    "    def fake_get(url):\n",
    "        return m\n",
    "\n",
    "    return fake_get\n",
    "\n",
    "@mock.patch('requests.get', get_fake_get(200, 'foo'))\n",
    "def test_foo():\n",
    "    r = requests.get('http://foo')\n",
    "    assert r.content == 'foo'\n",
    "\n",
    "@mock.patch('requests.get', get_fake_get(200, 'bar'))\n",
    "def test_foo():\n",
    "    r = requests.get('http://bar')\n",
    "    assert r.content == 'bar'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai2)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
